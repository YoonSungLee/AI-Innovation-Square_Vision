{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cifar10_실습.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YoonSungLee/AI-Innovation-Square_Vision/blob/master/Day%205_CNN%20%EC%9D%B4%ED%95%B4%20%EB%B0%8F%20%EC%B5%9C%EC%8B%A0%20%EA%B8%B0%EC%88%A0%20%EB%8F%99%ED%96%A5/Cifar10_%EC%8B%A4%EC%8A%B5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Ts8xn2YKPJm",
        "colab_type": "text"
      },
      "source": [
        "VGG의 단점 : Bottleneck<br>\n",
        "<br>\n",
        "(None, 224, 224, 32)<br>\n",
        "(None, 112, 112, 32)<br>\n",
        "(None, 112, 112, 64)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zj7PiHHeKesN",
        "colab_type": "text"
      },
      "source": [
        "Bottleneck 해결책 : maxpooling 전에 feature의 수를 2배로 증가<br>\n",
        "<br>\n",
        "(None, 224, 224, 32)<br>\n",
        "(None, 224, 224, 64)<br>\n",
        "(None, 112, 112, 64)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHMtnYN4JbzR",
        "colab_type": "code",
        "outputId": "98d4f312-684e-439d-9abd-e8ddf2178d3a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        }
      },
      "source": [
        "from __future__ import print_function\n",
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, BatchNormalization\n",
        "\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xN76jTnaJku7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 16\n",
        "num_classes = 10\n",
        "epochs = 25"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BuwjP0yeJlyu",
        "colab_type": "code",
        "outputId": "ee6f94c2-1809-4459-a730-f7775b4f2601",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "# The data, split between train and test sets:\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 10s 0us/step\n",
            "x_train shape: (50000, 32, 32, 3)\n",
            "50000 train samples\n",
            "10000 test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ICtLv_uZJoXe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-rfn1qzqJ5dW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 정규화\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iDFttU7cJvdh",
        "colab_type": "text"
      },
      "source": [
        "네트워크를 직접 설계해 보세요!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJRS-NhGPyG2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# n_kernels을 설정하면 모델 설계 시 유용\n",
        "# BatchNormalization 설정\n",
        "# 모델이 깊어질 경우 dimension 주의\n",
        "# Flatten 대신 GlobalAveragePooling2D 사용 가능(모델이 깊을 경우)\n",
        "\n",
        "\n",
        "def create_model():\n",
        "    model = Sequential()\n",
        "    # N, 32, 32, 3\n",
        "    model.add(Conv2D(64, (3,3), input_shape=(32, 32, 3), activation='relu',\n",
        "                     kernel_initializer='he_normal'))\n",
        "    # N, 30, 30, 64\n",
        "    model.add(Conv2D(64, (3,3), activation='relu',\n",
        "                     kernel_initializer='he_normal'))\n",
        "    # N, 28, 28, 64\n",
        "    model.add(MaxPooling2D())\n",
        "    # N, 14, 14, 64\n",
        "    model.add(Conv2D(128, (3,3), activation='relu',\n",
        "                     kernel_initializer='he_normal'))\n",
        "    # N, 12, 12, 128\n",
        "    model.add(Conv2D(128, (3,3), activation='relu',\n",
        "                     kernel_initializer='he_normal'))\n",
        "    # N, 10, 10, 128\n",
        "    model.add(MaxPooling2D())\n",
        "    # N, 5, 5, 128\n",
        "    model.add(Flatten())\n",
        "    # N, 3200\n",
        "    model.add(Dense(10, activation='softmax', kernel_initializer='glorot_uniform'))\n",
        "    # N, 10\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BryLvZkmSXJl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = create_model()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tTTlF8aFH4gR",
        "colab_type": "code",
        "outputId": "18335535-70f3-4d59-d86a-de223a740b7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_14\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_60 (Conv2D)           (None, 30, 30, 64)        1792      \n",
            "_________________________________________________________________\n",
            "conv2d_61 (Conv2D)           (None, 28, 28, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_26 (MaxPooling (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_62 (Conv2D)           (None, 12, 12, 128)       73856     \n",
            "_________________________________________________________________\n",
            "conv2d_63 (Conv2D)           (None, 10, 10, 128)       147584    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_27 (MaxPooling (None, 5, 5, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_5 (Flatten)          (None, 3200)              0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 10)                32010     \n",
            "=================================================================\n",
            "Total params: 292,170\n",
            "Trainable params: 292,170\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NT5sENY6KNrG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zd1E5FY4JqQG",
        "colab_type": "code",
        "outputId": "e7825c0f-3c1a-4144-bb97-cf8ded5cf11f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "# Let's train the model using RMSprop\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lkA0Pd6vJ_IO",
        "colab_type": "code",
        "outputId": "24d62b66-12b3-4422-d43a-10c0602c82e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "trained_model = model.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          validation_data=(x_test, y_test),\n",
        "          shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/25\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "50000/50000 [==============================] - 31s 614us/step - loss: 1.5546 - acc: 0.4409 - val_loss: 1.3253 - val_acc: 0.5186\n",
            "Epoch 2/25\n",
            "50000/50000 [==============================] - 17s 337us/step - loss: 1.1871 - acc: 0.5843 - val_loss: 1.1040 - val_acc: 0.6140\n",
            "Epoch 3/25\n",
            "50000/50000 [==============================] - 16s 329us/step - loss: 1.0195 - acc: 0.6463 - val_loss: 0.9757 - val_acc: 0.6663\n",
            "Epoch 4/25\n",
            "50000/50000 [==============================] - 17s 331us/step - loss: 0.9089 - acc: 0.6880 - val_loss: 0.9224 - val_acc: 0.6819\n",
            "Epoch 5/25\n",
            "50000/50000 [==============================] - 17s 330us/step - loss: 0.8203 - acc: 0.7179 - val_loss: 0.9179 - val_acc: 0.6826\n",
            "Epoch 6/25\n",
            "50000/50000 [==============================] - 16s 328us/step - loss: 0.7532 - acc: 0.7433 - val_loss: 0.8248 - val_acc: 0.7190\n",
            "Epoch 7/25\n",
            "50000/50000 [==============================] - 17s 331us/step - loss: 0.6939 - acc: 0.7636 - val_loss: 0.8136 - val_acc: 0.7178\n",
            "Epoch 8/25\n",
            "50000/50000 [==============================] - 16s 327us/step - loss: 0.6414 - acc: 0.7802 - val_loss: 0.7843 - val_acc: 0.7337\n",
            "Epoch 9/25\n",
            "50000/50000 [==============================] - 17s 332us/step - loss: 0.5948 - acc: 0.7990 - val_loss: 0.7523 - val_acc: 0.7437\n",
            "Epoch 10/25\n",
            "50000/50000 [==============================] - 16s 325us/step - loss: 0.5534 - acc: 0.8117 - val_loss: 0.7523 - val_acc: 0.7459\n",
            "Epoch 11/25\n",
            "50000/50000 [==============================] - 16s 325us/step - loss: 0.5122 - acc: 0.8249 - val_loss: 0.7226 - val_acc: 0.7565\n",
            "Epoch 12/25\n",
            "50000/50000 [==============================] - 16s 330us/step - loss: 0.4777 - acc: 0.8366 - val_loss: 0.7252 - val_acc: 0.7622\n",
            "Epoch 13/25\n",
            "50000/50000 [==============================] - 16s 327us/step - loss: 0.4430 - acc: 0.8516 - val_loss: 0.7411 - val_acc: 0.7594\n",
            "Epoch 14/25\n",
            "50000/50000 [==============================] - 16s 324us/step - loss: 0.4088 - acc: 0.8621 - val_loss: 0.7360 - val_acc: 0.7656\n",
            "Epoch 15/25\n",
            "50000/50000 [==============================] - 16s 327us/step - loss: 0.3784 - acc: 0.8727 - val_loss: 0.7624 - val_acc: 0.7615\n",
            "Epoch 16/25\n",
            "50000/50000 [==============================] - 17s 331us/step - loss: 0.3489 - acc: 0.8826 - val_loss: 0.7856 - val_acc: 0.7622\n",
            "Epoch 17/25\n",
            "50000/50000 [==============================] - 16s 329us/step - loss: 0.3204 - acc: 0.8932 - val_loss: 0.7790 - val_acc: 0.7654\n",
            "Epoch 18/25\n",
            "50000/50000 [==============================] - 16s 327us/step - loss: 0.2937 - acc: 0.9029 - val_loss: 0.8397 - val_acc: 0.7563\n",
            "Epoch 19/25\n",
            "50000/50000 [==============================] - 16s 328us/step - loss: 0.2661 - acc: 0.9111 - val_loss: 0.8824 - val_acc: 0.7585\n",
            "Epoch 20/25\n",
            "50000/50000 [==============================] - 17s 337us/step - loss: 0.2444 - acc: 0.9194 - val_loss: 0.8283 - val_acc: 0.7688\n",
            "Epoch 21/25\n",
            "50000/50000 [==============================] - 16s 329us/step - loss: 0.2202 - acc: 0.9274 - val_loss: 0.8316 - val_acc: 0.7706\n",
            "Epoch 22/25\n",
            "50000/50000 [==============================] - 17s 330us/step - loss: 0.1983 - acc: 0.9351 - val_loss: 0.8799 - val_acc: 0.7698\n",
            "Epoch 23/25\n",
            "50000/50000 [==============================] - 16s 326us/step - loss: 0.1776 - acc: 0.9424 - val_loss: 0.9524 - val_acc: 0.7626\n",
            "Epoch 24/25\n",
            "50000/50000 [==============================] - 16s 329us/step - loss: 0.1599 - acc: 0.9481 - val_loss: 0.9458 - val_acc: 0.7618\n",
            "Epoch 25/25\n",
            "50000/50000 [==============================] - 16s 326us/step - loss: 0.1435 - acc: 0.9549 - val_loss: 0.9507 - val_acc: 0.7714\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KAnM6dDEKPMu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs_range = range(25)\n",
        "validation_accuracy = trained_model.history['val_acc']\n",
        "training_accuracy = trained_model.history['acc']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AUEiUJm3KUbR",
        "colab_type": "code",
        "outputId": "9b52cca8-272a-4753-a71f-508428e894a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(epochs_range, training_accuracy, 'b+', label='training accuracy')\n",
        "# ‘bo’는 파란색 점을 의미합니다\n",
        "plt.plot(epochs_range, validation_accuracy, 'bo', label='validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Validation accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEGCAYAAACKB4k+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nlJKCiIhE/TdrmUJTXW9gIQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aU9keG2bKY9j",
        "colab_type": "code",
        "outputId": "2025eaa4-5e8e-4b16-8607-f761a67ed45e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "scores = model.evaluate(x_test, y_test, verbose=1)\n",
        "print('Test loss:', scores[0])\n",
        "print('Test accuracy:', scores[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 1s 89us/step\n",
            "Test loss: 0.9507133054256439\n",
            "Test accuracy: 0.7714\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ute631LApFtp",
        "colab_type": "text"
      },
      "source": [
        "# Kaggle : intel image classification tutorial feedback"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1U2Ff-QQpx2Y",
        "colab_type": "text"
      },
      "source": [
        "* activation function = 'relu' 사용 시, kernel_initialzer = he_normal 사용\n",
        "* MaxPooling2D의 사이즈는 2 by 2\n",
        "* Conv2D filter 사이즈는 2의 지수\n",
        "* Conv2D filter 사이즈를 변수를 통해 간편하게 설정\n",
        "* 마지막 Dense layer 각각 Dropout\n",
        "* BatchNormalization\n",
        "* Image Classification Problem : padding='valid'"
      ]
    }
  ]
}